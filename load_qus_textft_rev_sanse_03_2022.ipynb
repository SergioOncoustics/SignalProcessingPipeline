{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"radiomics.glcm\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Inputs\n",
    "# list of patients: (h3, c3, f03, f23, f33, f43)\n",
    "# List of patient indexes: TRAIN (hr,cr,f0r,f2r,f3r,f4r) OR TEST (he2,ce2,f0e2,f2e2,f3e2,f4e2)\n",
    "# corresponding label: (0,1,2,3)\n",
    "\n",
    "#Returns\n",
    "# Test or Train data \n",
    "# Test or Train labels\n",
    "\n",
    "def load_qus_textft(patient_list, patient_indexes, label,kpalist, caplist,ep):\n",
    "    ''' sanse: Calculating all statistics, applying masks'''\n",
    "    windtoframe=[]\n",
    "    datavidtopat = []\n",
    "    datavid = []\n",
    "    datalabvid = []\n",
    "    dataframetovid = []\n",
    "    sergg=0\n",
    "    shapedat=[]\n",
    "    dataframe = []\n",
    "    Bmodeout=[]\n",
    "    datawind = []\n",
    "    datalabframe = []\n",
    "    qusweights=[]\n",
    "    rfweights=[]\n",
    "    quantweights=[]    \n",
    "    winddats=[]\n",
    "    Ps_out=[]\n",
    "    shapedat2=[]\n",
    "    for m in tqdm_notebook(range(0,np.shape(patient_indexes)[0])): \n",
    "        #DF = Load_QUS_Loc(c3[cr[m]:cr[m]+1])\n",
    "        #try:\n",
    "        #    DF['Case']\n",
    "        #    print(1)\n",
    "        #except:\n",
    "        #    continue\n",
    "        '''\n",
    "        try:\n",
    "            QUS_list, QUANT_list, RF_list = Dat_nump_loader(patient_list[patient_indexes[m]])\n",
    "        except:\n",
    "            try:\n",
    "                QUS_list, QUANT_list, RF_list = Dat_nump_loaderval(patient_list[patient_indexes[m]])\n",
    "            except:\n",
    "                print(patient_list[patient_indexes[m]])\n",
    "        '''\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "        \n",
    "        \n",
    "        #Data Loading,\n",
    "        #for some reason it often doesn't work the first time around, hence the try except\n",
    "        \n",
    "        \n",
    "        try:\n",
    "#             with parallel_backend('multiprocessing'):\n",
    "#                 QUS_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_qus_video_direct)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "#             #print('QUS_list shape', np.shape(QUS_list)[0])\n",
    "            \n",
    "#             with parallel_backend('multiprocessing'):\n",
    "#                 RF_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_rf_video_direct)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "#             #print('RF_list shape', np.shape(RF_list)[0])\n",
    "           \n",
    "#             with parallel_backend('multiprocessing'):\n",
    "#                 QUANT_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_quant_video_direct)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            with parallel_backend('multiprocessing'):\n",
    "                QUS_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_qus_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            #print('QUS_list shape', np.shape(QUS_list)[0])\n",
    "            \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                RF_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_rf_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            #print('RF_list shape', np.shape(RF_list)[0])\n",
    "           \n",
    "            #with parallel_backend('multiprocessing'):\n",
    "            #    QUANT_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_quant_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                Full_Mask = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_fullmask_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                Bad_Mask = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_prcntmask_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            with parallel_backend('multiprocessing'):\n",
    "                PS_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_ps_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "\n",
    "    \n",
    "    \n",
    "        except:\n",
    "        \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                QUS_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_qus_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            #print('QUS_list shape', np.shape(QUS_list)[0])\n",
    "            \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                RF_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_rf_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            #print('RF_list shape', np.shape(RF_list)[0])\n",
    "           \n",
    "            #with parallel_backend('multiprocessing'):\n",
    "            #    QUANT_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_quant_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                Full_Mask = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_fullmask_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "            \n",
    "            with parallel_backend('multiprocessing'):\n",
    "                Bad_Mask = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_prcntmask_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "\n",
    "            with parallel_backend('multiprocessing'):\n",
    "                PS_list = Parallel(n_jobs=num_cores,mmap_mode='r+')(delayed(load_ps_video_direct2)(patient_list[patient_indexes[m]],info_dict[patient_list[patient_indexes[m]]]['videos'][ii]) for ii in range(0,len(info_dict[patient_list[patient_indexes[m]]]['videos'])) )\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    " \n",
    "        \n",
    "        \n",
    "        datavidtopat.append(np.shape(RF_list)[0])\n",
    "\n",
    "                \n",
    "        for r in range(0,np.shape(RF_list)[0]):#Iterate through the videos\n",
    "            prep=video_shadowing_quicker((RF_list[r]), 80, 350, 200, 0.08, 0.18) #get the shadowing percentage for each frame\n",
    "            \n",
    "            if np.shape(RF_list[r])[0]==0:#remove videos with 0 frames\n",
    "                datavidtopat[np.shape(datavidtopat)[0]-1]=datavidtopat[np.shape(datavidtopat)[0]-1]-1\n",
    "                continue\n",
    "#             elif np.max(prep)==0:\n",
    "#                 datavidtopat[np.shape(datavidtopat)[0]-1]=datavidtopat[np.shape(datavidtopat)[0]-1]-1\n",
    "#                 continue\n",
    "            #quantweights.append(prep)\n",
    "\n",
    "            Rf_list2=[]\n",
    "            #Quant_list2=[]\n",
    "            Qus_list2=[]\n",
    "            Qus_list2=QUS_list[r]\n",
    "            Rf_list2=RF_list[r]\n",
    "            predicted_mask_bad=Bad_Mask[r]\n",
    "            predicted_mask=Full_Mask[r]\n",
    "            Ps_list2=PS_list[r]\n",
    "            \n",
    "            '''\n",
    "            try:\n",
    "                Bmode = rf2bmode(Rf_list2)\n",
    "            except:\n",
    "                datavidtopat[m]=datavidtopat[m]-1\n",
    "                continue\n",
    "            '''\n",
    "            #prcessing to create the bmodes that we save and work on\n",
    "            \n",
    "            Bmode2 = np.array([(rf2bmode(Rf_list2[q,:,:])) for q in range(0,np.shape(Rf_list2)[0])])#rf2bmode(ModeIM)#\n",
    "            '''\n",
    "            try:\n",
    "                Bmode = rf2bmode(Rf_list2)\n",
    "            except:\n",
    "                datavidtopat[m]=datavidtopat[m]-1\n",
    "                continue\n",
    "            '''\n",
    "            bmode2=np.reshape(Bmode2,(np.shape(Bmode2)[0],np.shape(Bmode2)[1],np.shape(Bmode2)[2],1))\n",
    "            '''sanse: bmode (saved for later), bmode2 (used for practical calculation)'''\n",
    "            \n",
    "            \n",
    "            ler2 = 20 * np.log10( np.abs(1 + hilbert(Rf_list2,axis=1) ))\n",
    "            bmode = np.array([lee_filter(ler2[ft,:,:],[12,6]) for ft in range(Rf_list2.shape[0])])#basic generation\n",
    "\n",
    "            Depth_enchancer = np.ones((2928), dtype=\"float\")\n",
    "            Depth_enchancer[:100] = 0.75\n",
    "            Depth_enchancer[100:300] = np.linspace(0.75,1,num=len(Depth_enchancer[100:300]))\n",
    "            Depth_enchancer[300:] = 1\n",
    "            Depth_enchancer=np.reshape(Depth_enchancer,(1,-1,1))#a version of TGC\n",
    "            #Depth_enchancer_2D = np.transpose([Depth_enchancer]*192)[0,:,:]\n",
    "\n",
    "            bmode[bmode < 0] = 0\n",
    "            bmode=bmode*Depth_enchancer\n",
    "            #print(np.shape(bmode))\n",
    "            dats=scanconvert2(bmode,imgInfo)#Efficient scanconversion\n",
    "            dats2=resize(dats,(np.shape(dats)[0],175,175))#resizing for the sake of space\n",
    "            \n",
    "            \n",
    "            predicted_mask_bad[(predicted_mask_bad<0.5).nonzero()]=0#thresholding the mask we use for liver percentage\n",
    "            predicted_mask_bad[(predicted_mask_bad).nonzero()]=1\n",
    "            '''sanse: mask liver percentage calculations'''\n",
    "            \n",
    "            \n",
    "           \n",
    "            predicted_mask[(predicted_mask<0.5).nonzero()]=0#thresholding the map we use for masking\n",
    "            predicted_mask[(predicted_mask).nonzero()]=1\n",
    "            '''sanse: for actual masking'''\n",
    "            \n",
    "            #Generating the maping look up table we use for the simple stats\n",
    "            armap2=np.arange(0,3904)#1152)#2304\n",
    "            armap2=np.reshape(armap2,(-1,64))\n",
    "            armap2=np.repeat(armap2,3,axis=1)\n",
    "            armap2=np.repeat(armap2,48,axis=0)#61#122\n",
    "            '''sanse: mapping the simple statistical parameters (turn 2D mask into 1D mask)'''\n",
    "\n",
    "            #Generating the mapping look up table we use for the QUS\n",
    "            armap=np.arange(0,1152)#1152)#2304\n",
    "            armap=np.reshape(armap,(-1,48))\n",
    "            armap=np.repeat(armap,4,axis=1)\n",
    "            armap=np.repeat(armap,122,axis=0)#61#122\n",
    "            '''sanse: mapping the qus parameters'''\n",
    "            \n",
    "            if np.max(predicted_mask)<0.5:#if the mask finds 0 liver, skip the video\n",
    "                datavidtopat[m]=datavidtopat[m]-1\n",
    "                continue\n",
    "            '''sanse: if there are no pixels with 50% probability skip video'''\n",
    "                \n",
    "            #generating thresholds for bining GLCM\n",
    "            heft=np.array([(                 np.unique(armap[(predicted_mask[q,:,:]>=0.5).nonzero()])          ) for q in range(0,np.shape(predicted_mask)[0])])\n",
    "            qus_premp=np.array([(            Qus_list2[q,heft[q],:]               ) for q in range(0,np.shape(Rf_list2)[0])])\n",
    "            qus_premp=np.vstack(qus_premp)\n",
    "#             print(np.shape(qus_premp))\n",
    "            ep1=eodev22(qus_premp,64)\n",
    "            '''sanse: binning thresholds per video, not per patient'''\n",
    "            \n",
    "            datalabvid.append([label,kpalist[patient_indexes[m]],caplist[patient_indexes[m]]])#video level labels\n",
    "            dataframetovid.append(np.shape(Rf_list2)[0])#frame to vid\n",
    "            \n",
    "            \n",
    "            for i in range(0,np.shape(Rf_list2)[0]):#itterate through each frame\n",
    "                eh6=predicted_mask[i,:,:]#get the mask for the frame\n",
    "                \n",
    "                eh6=np.reshape(eh6,(2928,192)) '''sanse: unnecessary'''\n",
    "                '''sanse: apply masks to maps'''\n",
    "                liv=armap[(eh6>=0.5).nonzero()]# get the qus windows from the mask\n",
    "                liv=np.unique(liv) '''sanse: 1d mask for qus'''\n",
    "                #print(np.size(liv))\n",
    "                if np.size(liv)<2:#if only 1 window is found, skip the frame, account for the change in itterators\n",
    "                    dataframetovid[np.shape(dataframetovid)[0]-1]=dataframetovid[np.shape(dataframetovid)[0]-1]-1\n",
    "                    if dataframetovid[np.shape(dataframetovid)[0]-1]==0:\n",
    "                        dataframetovid=dataframetovid[0:np.shape(dataframetovid)[0]-2]\n",
    "                        datavidtopat[m]=datavidtopat[m]-1\n",
    "                        datavid=datavid[0:np.shape(datavid)[0]-2]\n",
    "                        print(type(datalabvid))\n",
    "                        datalabvid=datalabvid[0:np.shape(datalabvid)[0]-2]\n",
    "                        print(type(datalabvid))\n",
    "                    #print(dataframetovid[np.shape(dataframetovid)[0]-1])=\n",
    "                    continue\n",
    "                    #liv=armap[(eh6>0.4).nonzero()]\n",
    "                    #liv=np.unique(liv)\n",
    "                #print(np.shape(predicted_mask_bad))\n",
    "                shapedat.append(copy.deepcopy(liv))#save the mapping info\n",
    "                datavid.append(np.sum(predicted_mask_bad[i,:,:])/102400)#get the liver percentage according to the relevent mask\n",
    "                '''sanse: check percentages (102400 is the number of pixels in the image)'''\n",
    "\n",
    "                contours, hierarchy= cv2.findContours(predicted_mask[i].astype(\"uint8\"),cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)#.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "                ''' sanse: check if more than one mask is available in segmentation (use it for filtering) (check)'''\n",
    "                stuffir=len(contours)# grab the number of shape in the mask\n",
    "                quantweights.append(prep[i])#take the shadow percentage for this frame\n",
    "                \n",
    "                Bmodeout.append(copy.deepcopy(dats2[i]))#grab this frames bmode\n",
    "                \n",
    "                \n",
    "                '''\n",
    "                From here is the code neccesary for binning, reshapping, and masking the QUS maps for GLCM calculations \n",
    "                '''\n",
    "\n",
    "                '''sanse: intermediate steps of glcm (ab is a mask)'''\n",
    "                '''sanse: PyRadiomics implementation of GLCM'''\n",
    "                ab=np.zeros(1152)#2304\n",
    "                ab[liv]=1\n",
    "                ab=np.reshape(ab,(24,48))\n",
    "                #print(np.shape(ab))\n",
    "                ab=np.repeat(ab,4,axis=1)\n",
    "                ab=np.repeat(ab,122,axis=0)\n",
    "                #print(\"ab before:\",np.shape(ab))\n",
    "                ## Downsample mask to match with downsampled scanconverted image\n",
    "                ab=ab[::4,::4]\n",
    "                #print(\"ab after downsampling:\",np.shape(ab))\n",
    "                ## Call scanconvert on ab\n",
    "                ab = scanconvert(ab,imgInfo2)\n",
    "                #print(\"ab after scanconvert:\",np.shape(ab))\n",
    "                ## Cropping option (comment out next two lines to not crop)\n",
    "                a,b = (ab).nonzero()\n",
    "                ab = ab[np.min(a):np.max(a), np.min(b):np.max(b)]\n",
    "\n",
    "                try:\n",
    "                    data_spacing=[1,1]\n",
    "                    sitk_mask = sitk.GetImageFromArray(ab)\n",
    "                    sitk_mask.SetSpacing((float(data_spacing[0]), float(data_spacing[1]) ))#, float(data_spacing[2]) ))\n",
    "                    sitk_mask = sitk.JoinSeries(sitk_mask)\n",
    "                    sitk_mask = sitk.Cast(sitk_mask, sitk.sitkInt32) # MAKE SURE IT IS CASTED IN I\n",
    "                except:\n",
    "                    print(\"Error creating mask in inner-loop\")\n",
    "                    continue\n",
    "                                      \n",
    "                                      \n",
    "\n",
    "                Qus_list2[np.isnan(Qus_list2)]=0\n",
    "                Qus_list2[np.isinf(Qus_list2)]=1\n",
    "                windtoframe.append(np.shape(liv))\n",
    "                QUSRel=copy.deepcopy(Qus_list2[i,:,:])\n",
    "                QUSRel=badmathflat2(QUSRel, ep1, 64)\n",
    "                #print(np.shape(np.unique(QUSRel)))\n",
    "\n",
    "                #QUSRel=badmathflat(QUSRel, ep, 64)\n",
    "                ShapedQUS=np.reshape(QUSRel,(24,48,17))#48\n",
    "                '''sanse: applying mask to qus for the purpose of glcm'''\n",
    "                #ShapedQUS=np.reshape(QUSRel,(24,48,17))#48\n",
    "                \n",
    "#                 ShapedQUS=np.repeat(ShapedQUS,61,axis=0)\n",
    "#                 ShapedQUS=ShapedQUS[::2,:,:]\n",
    "                \n",
    "#                 ShapedQUS = np.asarray([scanconvert(ShapedQUS[:,:,b],imgInfo) for b in range(0,17)])\n",
    "#                 #ShapedQUS2 = ShapedQUS2.transpose(1,2,0)#np.reshape(ShapedQUS2,(np.shape(ShapedQUS2)[1],np.shape(ShapedQUS2)[2],np.shape(ShapedQUS2)[0]))\n",
    "#                 ## Cropping option\n",
    "#                 ShapedQUS = ShapedQUS[:,np.min(a):np.max(a), np.min(b):np.max(b)]\n",
    "\n",
    "\n",
    "#                 #print(np.shape(ShapedQUS))\n",
    "                \n",
    "                \n",
    "                ab2=np.arange(1,1153)#1152)#2304\n",
    "                ab2=np.reshape(ab2,(-1,48))\n",
    "                ab2=np.reshape(ab2,(24,48))#(24,48))#(48,48))\n",
    "                ab2=np.repeat(ab2,61,axis=0)\n",
    "                ab2=ab2[::2,:]\n",
    "\n",
    "                ab2 = scanconvert(ab2,imgInfo2)#np.asarray([scanconvert(ShapedQUS[:,:,p],imgInfo) for p in range(0,17)])\n",
    "                gelem=np.zeros([61, 90, 17])\n",
    "                #r=np.zeros((np.shape(self.QUSVal[frameNum].m)))\n",
    "                [jj,ii]=(ab2>=1).nonzero()\n",
    "                jj=jj.astype(int)\n",
    "                ii=ii.astype(int)\n",
    "                #ab2=ab2-1\n",
    "                gelem[jj,ii,:]=QUSRel[ab2[jj,ii].astype(int)-1,:]#,self.QUSC]\n",
    "                gelem=gelem.astype(int)\n",
    "                ShapedQUS=gelem[np.min(a):np.max(a), np.min(b):np.max(b),:]\n",
    "                '''sanse: glcm intermediate steps ... reshaping'''\n",
    "                \n",
    "                \n",
    "                \n",
    "                qus_temp=Qus_list2[i,liv,:]\n",
    "                #print(np.shape(qus_temp))\n",
    "                rfmask=copy.deepcopy(eh6)\n",
    "                rfmask[(rfmask==0).nonzero()]=np.nan\n",
    "                Mink_FD = Minkowski_FD(bmode2[i,:,:,0]*rfmask)\n",
    "                '''sanse: fractal features'''\n",
    "                #rfmask=copy.deepcopy(eh6)\n",
    "                #rfmask[(rfmask==0).nonzero()]=np.nan\n",
    "                masked_rf_array = Rf_list2[i]*rfmask\n",
    "                kern_rad = [1]#[1]#[2]#[5],[7],[10],[15],[20]\n",
    "                N_GL = 64\n",
    "                ## Vary distances: [1]#[2]#[4]#[6]#[8]#[10]\n",
    "                settings = {'binCount':N_GL,\n",
    "                #'binWidth': 128,\n",
    "                'interpolator': sitk.sitkBSpline,\n",
    "                # 'symmetricalGLCM': False,\n",
    "                # 'weightingNorm': 'euclidean',\n",
    "                'distances': [4],\n",
    "                'kernelRadius': kern_rad}\n",
    "\n",
    "                '''sanse: fractal features and GLCM are a bit mixed together in the code, but has no impact (revise)'''\n",
    "\n",
    "                Higuchi_FD=[]\n",
    "                for k in range(0,np.shape(Rf_list2[i])[1]):\n",
    "                    Higuchi_FD.append(hfda.measure(masked_rf_array[~np.isnan(masked_rf_array[:,k]),k],16))\n",
    "                    '''Higuchi features: hdfa package (there will be paper and everything)'''\n",
    "                try:    \n",
    "                    '''sanse: pyradiomics functions'''\n",
    "                    glcm_data=(np.array([glcm.RadiomicsGLCM(sitk.JoinSeries(sitk.GetImageFromArray(ShapedQUS[:,:,b])), sitk_mask,**settings).execute()  for b in range(0,17)]))#a=frame, b=windows #sitk_mask #range(0,np.shape(liv)[0]) ==> (Quant_list2[i,liv(b),:,:] to be moved in for-loop below\n",
    "                    glcm_data_arr=np.array([(e['Autocorrelation'], e['ClusterProminence'], e['ClusterShade'], e['ClusterTendency'],e['Contrast'], e['Correlation'], e['DifferenceAverage'], e['DifferenceEntropy'],e['DifferenceVariance'], e['Id'], e['Idm'], e['Idmn'],e['Idn'], e['Imc1'], e['Imc2'], e['InverseVariance'],e['JointAverage'], e['JointEnergy'], e['JointEntropy'], e['MCC'],e['MaximumProbability'], e['SumAverage'], e['SumEntropy'], e['SumSquares']) for e in glcm_data]) #nert is size of number of windows in a video\n",
    "                    ngtdm_data=(np.array([ngtdm.RadiomicsNGTDM(sitk.JoinSeries(sitk.GetImageFromArray(ShapedQUS[:,:,b])), sitk_mask,**settings).execute()  for b in range(0,17)]))\n",
    "                    ngtdm_data_arr=np.array([(e['Coarseness'], e['Busyness'], e['Complexity'], e['Strength']) for e in ngtdm_data])\n",
    "                except:\n",
    "                    glcm_data_arr=np.ones([408,1])\n",
    "                    ngtdm_data_arr=np.ones([68,1])\n",
    "                    '''sanse: in case the windows are too small it does not calculate '''\n",
    "                    \n",
    "                temp3=np.concatenate((np.percentile(qus_temp,10,axis=0),np.percentile(qus_temp,25,axis=0),np.percentile(qus_temp,75,axis=0)-np.percentile(qus_temp,25,axis=0),np.percentile(qus_temp,75,axis=0),np.percentile(qus_temp,90,axis=0),np.reshape(mode(qus_temp)[0],(np.shape(np.sum(qus_temp,axis=0)))),np.sum(qus_temp,axis=0),sps.skew(qus_temp,axis=0),np.median(qus_temp,axis=0),np.var(qus_temp,axis=0),np.std(qus_temp,axis=0),np.mean(qus_temp,axis=0),np.min(qus_temp,axis=0),np.max(qus_temp,axis=0)),axis=0)#,np.mean(glcm_data_arr[:,:],axis=0),np.mean(ngtdm_data_arr[:,:],axis=0)),axis=0)\n",
    "                '''sanse: skew as a number'''\n",
    "                #temp3=np.concatenate((np.sum(Qus_list2[i,:,:],axis=0),sps.skew(Qus_list2[i,:,:],axis=0),np.median(Qus_list2[i,:,:],axis=0),np.var(Qus_list2[i,:,:],axis=0),np.std(Qus_list2[i,:,:],axis=0),np.mean(Qus_list2[i,:,:],axis=0),np.min(Qus_list2[i,:,:],axis=0),np.max(Qus_list2[i,:,:],axis=0)),axis=0)\n",
    "                #temp3=[np.sum(Qus_list2[i,:,:],axis=1),sps.skew(Qus_list2[i,:,:],axis=1),np.median(Qus_list2[i,:,:],axis=1),np.var(Qus_list2[i,:,:],axis=1),np.std(Qus_list2[i,:,:],axis=1),np.mean(Qus_list2[i,:,:],axis=1),np.min(Qus_list2[i,:,:],axis=1),np.max(Qus_list2[i,:,:],axis=1)]\n",
    "                #nt2=nt2[use,:]\n",
    "                #print(np.shape(eh6))\n",
    "                #print(np.shape(liv))\n",
    "                #print(np.shape(qus_temp))\n",
    "                \n",
    "                glcm_data_arr=np.reshape(glcm_data_arr,(-1,))\n",
    "                ngtdm_data_arr=np.reshape(ngtdm_data_arr,(-1,))\n",
    "               \n",
    "                temp3 = np.hstack((np.nanmean(Higuchi_FD),Mink_FD,temp3,glcm_data_arr,ngtdm_data_arr))\n",
    "                dataframe.append(temp3)#Append the staistical summaries, GLCM etc. to frame level data\n",
    "                \n",
    "                datawind.append(qus_temp)# append the windows\n",
    "                datalabframe.append([label,kpalist[patient_indexes[m]],caplist[patient_indexes[m]]])\n",
    "                \n",
    "                ##noise\n",
    "                \n",
    "                rfweights.append(copy.deepcopy(stuffir))#append the shape counts to the output\n",
    "                '''\n",
    "                from here is the simple statistical map generation\n",
    "                masking and appending\n",
    "                '''\n",
    "                \n",
    "                \n",
    "                liv2=armap2[(eh6>=0.5).nonzero()]\n",
    "                liv2=np.unique(liv2)\n",
    "                \n",
    "                shapedat2.append(copy.deepcopy(liv2))#append the mapping info\n",
    "                \n",
    "                \n",
    "                rt=Rf_list2[i,:,:]\n",
    "                n=0#would be relevant if we ever figured out moving windows\n",
    "                b=48#61#61#122#64 #vertical window length\n",
    "                l=0#inital depth of window\n",
    "                h=0# would be relevant if I figured out moving windows\n",
    "                nat=setforrad3(rt) # creating the quantised dat in a pseudo guassian distribution, not the fastest but increadibly important for disease detection\n",
    "                sz=2928#the number of pixels vertically, important for size calculations\n",
    "                m=0#initializing a iterating variable\n",
    "                c=3#16#4#8#4 #horozontal window size\n",
    "                qa=int(sz/48)\n",
    "\n",
    "                #print(qa)\n",
    "                wlo=int(np.shape(rt)[1]/3)\n",
    "                #print(wlo)\n",
    "                #the next few parts are bit hard to explain, but:\n",
    "                #this is in one line converting the 2d RF (and quantized and phantom) data (that is in clarius' case a 2928 x 192)\n",
    "                #into a 3d array where the first dimension is the frame number,so specifically a 2304x61x4\n",
    "                #this allows all the math to become vectorizable (practically)\n",
    "                rf=np.array([(rt[(l+k*b)-n:(l+k*b)+b,(w*c):(w*c+c)]) for k in range(0,qa) for w in range(0,wlo) ])#np.array([((r[(l+i*b)-n:(l+i*b)+b,(w*c):(h*c+c)] )for w in range(0,48) )for i in range(0,48)])\n",
    "                #print(l+i*b)\n",
    "                l=0\n",
    "                natrf=np.array([(nat[(l+k*b)-n:(l+k*b)+b,(w*c):(w*c+c)]) for k in range(0,qa) for w in range(0,wlo) ])#np.array([((nat[(l+i*b)-n:(l+i*b)+b,(w*c):(h*c+c)] )for w in range(0,48) )for i in range(0,48)])\n",
    "                l=0\n",
    "                ph=np.array([(ph1[(l+k*b)-n:(l+k*b)+b,(w*c):(w*c+c)]) for k in range(0,qa) for w in range(0,wlo) ])\n",
    "                n1,n2,sr=NakaGamiParam2(rf,ph)\n",
    "                #print(np.shape(rf))\n",
    "                skews=skew(rf, axis=1)  '''sanse: skew parameter'''\n",
    "                #print(np.shape(skews))\n",
    "                skews=np.mean(skews,axis=1)\n",
    "                tefts2=np.shape(ph)[0]\n",
    "                #un,vals=np.unique(natrf,return_counts=True,axis=0)\n",
    "                heft=np.array([(np.unique(natrf[q,:,:],return_counts=True)          ) for q in range(0,tefts2)])#2304\n",
    "                vals=heft[:,1]\n",
    "                #print(np.shape(vals))\n",
    "                #print(np.shape(vals[0]))\n",
    "                ents=np.array([(entropy(vals[q])          ) for q in range(0,tefts2)])#23042304)])#entropy(vals)\n",
    "                '''sanse: entropy parameter'''\n",
    "                #print(np.shape(ents))\n",
    "                dats=np.hstack((np.reshape(skews,(-1,1)),np.reshape(ents,(-1,1)),np.reshape(sr,(-1,1)),np.reshape(n1,(-1,1)),np.reshape(n2,(-1,1))))\n",
    "                winddats.append(copy.deepcopy(dats[liv2,:]))#append the data\n",
    "                \n",
    "                \n",
    "                \n",
    "                ps_temp=np.reshape(Ps_list2[i,:,:,:],(-1,61))\n",
    "                ps_dat=ps_temp[liv,:]\n",
    "                Ps_out.append(copy.deepcopy(ps_dat))#append the power spectrum data\n",
    "                \n",
    "                \n",
    "                \n",
    "                #quantweights.append(1)\n",
    "                #print(\"Made it to the end\")\n",
    "                \n",
    "    return datavidtopat, datavid, datalabvid, dataframetovid, dataframe, datawind, datalabframe, rfweights, quantweights, windtoframe,shapedat,shapedat2,winddats,Ps_out,Bmodeout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
